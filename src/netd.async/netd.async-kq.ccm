/*
 * This is free and unencumbered software released into the public domain.
 *
 * Anyone is free to copy, modify, publish, use, compile, sell, or distribute
 * this software, either in source code form or as a compiled binary, for any
 * purpose, commercial or non-commercial, and by any means.
 *
 * In jurisdictions that recognize copyright laws, the author or authors of
 * this software dedicate any and all copyright interest in the software to the
 * public domain. We make this dedication for the benefit of the public at
 * large and to the detriment of our heirs and successors. We intend this
 * dedication to be an overt act of relinquishment in perpetuity of all present
 * and future rights to this software under copyright law.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
 * AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
 * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */

module;

/*
 * kq: lightweight wrapper around kqueue()/kevent() that allows provides
 * coroutine-based async i/o.
 */

#include <sys/types.h>
#include <sys/socket.h>
#include <sys/event.h>

#include <expected>
#include <functional>
#include <span>
#include <system_error>
#include <coroutine>
#include <cassert>
#include <unistd.h>

#include "defs.hh"

export module netd.async:kq;

import netd.util;
import :task;
import :fd;

namespace netd::kq {

/* kq represents a kqueue instance */
struct kqueue {
	fd kq_fd;
};

/* the global instance */
inline struct kqueue kq;

/*
 * this dispatch queue; this is a list of jobs to dispatch at the end of the
 * event loop.
 */

using dispatchcb = std::function<void()>;

std::vector<dispatchcb> jobs;

/* add a callback to the dispatch queue */
auto dispatch(dispatchcb handler) noexcept(
	std::is_nothrow_move_constructible_v<dispatchcb>) -> void
{
	try {
		jobs.emplace_back(std::move(handler));
	} catch (std::bad_alloc const &) {
		panic("kq: out of memory");
	}
}

auto runjobs() noexcept -> void
{
	/* the job list can be appended to while we're iterating */
	// NOLINTNEXTLINE(modernize-loop-convert)
	for (std::size_t i = 0; i < jobs.size(); ++i)
		jobs[i]();

	jobs.clear();
}

/*
 * initialise kq
 */
export auto init() noexcept -> std::expected<void, std::error_code>
{
	int fd_ = ::kqueuex(KQUEUE_CLOEXEC);
	if (fd_ == -1)
		return std::unexpected(error::from_errno());

	kq.kq_fd = fd(fd_);

	return {};
}

/* start the kq runner.  only returns on failure. */
export auto run() noexcept -> std::expected<void, std::error_code>
{
	auto handle = [](struct kevent &ev) noexcept {
		dispatch([=] noexcept {
			auto evaddr =
				reinterpret_cast<struct kevent *>(ev.ext[2]);
			std::memcpy(evaddr, &ev, sizeof(ev));

			auto coroaddr = reinterpret_cast<void *>(ev.ext[3]);
			auto coro =
				std::coroutine_handle<>::from_address(coroaddr);
			coro.resume();
		});
	};

	// run any jobs that were added before we started
	runjobs();

	struct kevent ev {};
	auto	      n = int{};
	while ((n = kevent(kq.kq_fd.get(), NULL, 0, &ev, 1, NULL)) != -1) {
		if (n > 0) {
			if (ev.ext[2] == 0)
				panic("kq_dispatch_event: unexpected event");
			handle(ev);
		}

		/* handle the kqdispatch() queue */
		runjobs();
	}

	panic("kqrun: kqueue failed: {}", error::strerror());
	return std::unexpected(error::from_errno());
}

/******************************************************************************
 * async (coroutine) interface.
 */

/*
 * make kevents awaitable
 */
struct wait_kevent {
	struct kevent *ev;

	explicit wait_kevent(struct kevent &ev_) noexcept : ev(&ev_) {}

	auto await_ready() noexcept -> bool
	{
		return false;
	}

	template<typename P>
	auto await_suspend(std::coroutine_handle<P> coro) noexcept -> bool
	{
		/*
		 * store the address of the kevent in ext[2].  this signals the
		 * kq dispatcher that it should copy the kevent there, and then
		 * resume the coro handle we place in ext[3].
		 */
		ev->ext[2] = reinterpret_cast<uintptr_t>(ev);
		ev->ext[3] = reinterpret_cast<uintptr_t>(coro.address());

		if (kevent(kq.kq_fd.get(), ev, 1, nullptr, 0, nullptr) == -1)
			panic("wait_kevent: kevent() failed: {}",
			      error::strerror());

		return true;
	}

	void await_resume() noexcept {}
};

auto operator co_await(struct kevent &ev)
{
	return wait_kevent(ev);
}

/*
 * start an async task in the background.  the task will run until completion,
 * then be destroyed.
 */
export auto run_task(jtask<void> &&tsk) noexcept -> void
{
	auto tsk_ = new (std::nothrow) jtask(std::move(tsk));

	tsk_->on_final_suspend(
		[=] { dispatch([=] noexcept { delete tsk_; }); });

	dispatch([=] noexcept { tsk_->_handle.resume(); });
}

/*
 * sleep until the given timer expires.
 */
export auto sleep(std::chrono::nanoseconds duration) -> task<void>
{
	struct kevent ev {};

	ev.ident = reinterpret_cast<uintptr_t>(&ev);
	ev.filter = EVFILT_TIMER;
	ev.fflags = NOTE_NSECONDS;
	ev.data = duration.count();
	ev.flags = EV_ADD | EV_ENABLE | EV_ONESHOT;

	co_await ev;
}

export template<typename Rep, typename Period>
auto sleep(std::chrono::duration<Rep, Period> duration) -> task<void>
{
	co_await sleep(
		std::chrono::duration_cast<std::chrono::nanoseconds>(duration));
}

/*
 * sleep until the given absolute time arrives.
 */
auto sleep_until(std::chrono::time_point<std::chrono::system_clock> when)
	-> task<void>
{
	struct kevent ev {};

	ev.ident = reinterpret_cast<uintptr_t>(&ev);
	ev.filter = EVFILT_TIMER;
	ev.fflags = NOTE_ABSTIME | NOTE_NSECONDS;
	ev.data = std::chrono::duration_cast<std::chrono::nanoseconds>(
			  when.time_since_epoch())
			  .count();
	ev.flags = EV_ADD | EV_ENABLE | EV_ONESHOT;

	co_await ev;
}

/*
 * wait for this fd to become readable.
 */
auto wait_readable(fd &fdesc) -> task<void>
{
	struct kevent ev {};

	ev.ident = (uintptr_t)fdesc.get();
	ev.filter = EVFILT_READ;
	ev.flags = EV_ADD | EV_ENABLE | EV_ONESHOT;

	co_await ev;
}

/*
 * wait for this fd to become writable.
 */
auto wait_writable(fd &fdesc) -> task<void>
{
	struct kevent ev {};

	ev.ident = (uintptr_t)fdesc.get();
	ev.filter = EVFILT_WRITE;
	ev.flags = EV_ADD | EV_ENABLE | EV_ONESHOT;

	co_await ev;
}

/*
 * read data into the provided buffer.
 */
export auto read(fd &fdesc, std::span<std::byte> buf)
	-> task<std::expected<std::size_t, std::error_code>>
{
	assert(buf.size() > 0);

	// keep trying the read until we get some data, or an error
	for (;;) {
		auto n = ::read(fdesc.get(), buf.data(), buf.size());

		if (n >= 0)
			co_return n;

		if (errno != EAGAIN)
			co_return std::unexpected(error::from_errno());

		co_await wait_readable(fdesc);
	}
}

/*
 * write data from the provided buffer.
 */
export auto write(fd &fdesc, std::span<std::byte const> buf)
	-> task<std::expected<std::size_t, std::error_code>>
{
	assert(!buf.empty());

	for (;;) {
		auto n = ::write(fdesc.get(), buf.data(), buf.size());

		if (n >= 0)
			co_return n;

		if (errno != EAGAIN)
			co_return std::unexpected(error::from_errno());

		co_await wait_writable(fdesc);
	}
}

/*
 * read a single message into the provided buffer.  reading will continue until
 * the entire message is received (MSG_EOR).
 *
 * returns the size of the message read, or error.  if the buffer is too small
 * to hold the message, the message is discarded and ENOSPC is returned.
 */
export [[nodiscard]] auto recvmsg(fd &fdesc, std::span<std::byte> buf)
	-> task<std::expected<std::size_t, std::error_code>>
{
	// the remaining buffer we can read into
	auto bufleft = buf;

	// try a single read from the fd.
	auto recv1 = [&](msghdr *msg) {
		auto iov = iovec{bufleft.data(), bufleft.size()};

		msg->msg_iov = &iov;
		msg->msg_iovlen = 1;

		// wait for some data to arrive
		auto n = ::recvmsg(fdesc.get(), msg, 0);
		return n;
	};

	/* read until we get either MSG_EOR or run out of buffer space */
	for (;;) {
		if (bufleft.empty())
			// out of space
			co_return std::unexpected(error::from_errno(ENOSPC));

		auto msg = msghdr{};

		switch (auto n = recv1(&msg)) {
		case 0:
			// end of file
			co_return 0u;

		case -1:
			if (errno != EAGAIN)
				co_return std::unexpected(error::from_errno());

			co_await wait_readable(fdesc);
			break;

		default:
			// we read some data, adjust the remaining buffer space
			bufleft = bufleft.subspan(static_cast<std::size_t>(n));

			if ((msg.msg_flags & MSG_EOR) == MSG_EOR)
				// we read an entire message
				co_return buf.size() - bufleft.size();
			break;
		}

		// we didn't get the complete message, try again
	}
}

/*
 * accept a connection on the given server socket.  the arguments are as
 * described in accept4(2).
 */
export [[nodiscard]] auto
accept4(fd &server_fd, sockaddr *addr, socklen_t *addrlen, int flags)
	-> task<std::expected<fd, std::error_code>>
{
	for (;;) {
		// try accepting forever until we get an error, or succeed.
		auto newfd = ::accept4(server_fd.get(), addr, addrlen, flags);

		if (newfd >= 0)
			co_return fd(newfd);

		if (errno != EAGAIN)
			co_return std::unexpected(error::from_errno());

		// wait for the fd to become readable
		co_await wait_readable(server_fd);
	}
}

} // namespace netd::kq
